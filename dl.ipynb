{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset split - Train: 40000, Validation: 20000\n",
      "Created dataset split - Train: 50000, Validation: 10000\n",
      "Created dataset split - Train: 30000, Validation: 30000\n",
      "Created dataset split - Train: 55000, Validation: 5000\n",
      "Created dataset split - Train: 58000, Validation: 2000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define dataset splits\n",
    "splits = [\n",
    "    (40000, 20000),\n",
    "    (50000, 10000),\n",
    "    (30000, 30000),\n",
    "    (55000, 5000),\n",
    "    (58000, 2000)\n",
    "]\n",
    "\n",
    "# Create different train-validation splits\n",
    "datasets_splits = []\n",
    "\n",
    "for train_size, val_size in splits:\n",
    "    train_set, val_set = random_split(mnist_train, [train_size, val_size])\n",
    "    datasets_splits.append((train_set, val_set))\n",
    "    print(f\"Created dataset split - Train: {train_size}, Validation: {val_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train: 40000, Validation: 20000 ===\n",
      "Batch Size: 10 --> Train Batches: 4000, Validation Batches: 2000\n",
      "Batch Size: 25 --> Train Batches: 1600, Validation Batches: 800\n",
      "Batch Size: 64 --> Train Batches: 625, Validation Batches: 313\n",
      "Batch Size: 128 --> Train Batches: 313, Validation Batches: 157\n",
      "Batch Size: 256 --> Train Batches: 157, Validation Batches: 79\n",
      "Batch Size: 512 --> Train Batches: 79, Validation Batches: 40\n",
      "\n",
      "=== Train: 50000, Validation: 10000 ===\n",
      "Batch Size: 10 --> Train Batches: 5000, Validation Batches: 1000\n",
      "Batch Size: 25 --> Train Batches: 2000, Validation Batches: 400\n",
      "Batch Size: 64 --> Train Batches: 782, Validation Batches: 157\n",
      "Batch Size: 128 --> Train Batches: 391, Validation Batches: 79\n",
      "Batch Size: 256 --> Train Batches: 196, Validation Batches: 40\n",
      "Batch Size: 512 --> Train Batches: 98, Validation Batches: 20\n",
      "\n",
      "=== Train: 30000, Validation: 30000 ===\n",
      "Batch Size: 10 --> Train Batches: 3000, Validation Batches: 3000\n",
      "Batch Size: 25 --> Train Batches: 1200, Validation Batches: 1200\n",
      "Batch Size: 64 --> Train Batches: 469, Validation Batches: 469\n",
      "Batch Size: 128 --> Train Batches: 235, Validation Batches: 235\n",
      "Batch Size: 256 --> Train Batches: 118, Validation Batches: 118\n",
      "Batch Size: 512 --> Train Batches: 59, Validation Batches: 59\n",
      "\n",
      "=== Train: 55000, Validation: 5000 ===\n",
      "Batch Size: 10 --> Train Batches: 5500, Validation Batches: 500\n",
      "Batch Size: 25 --> Train Batches: 2200, Validation Batches: 200\n",
      "Batch Size: 64 --> Train Batches: 860, Validation Batches: 79\n",
      "Batch Size: 128 --> Train Batches: 430, Validation Batches: 40\n",
      "Batch Size: 256 --> Train Batches: 215, Validation Batches: 20\n",
      "Batch Size: 512 --> Train Batches: 108, Validation Batches: 10\n",
      "\n",
      "=== Train: 58000, Validation: 2000 ===\n",
      "Batch Size: 10 --> Train Batches: 5800, Validation Batches: 200\n",
      "Batch Size: 25 --> Train Batches: 2320, Validation Batches: 80\n",
      "Batch Size: 64 --> Train Batches: 907, Validation Batches: 32\n",
      "Batch Size: 128 --> Train Batches: 454, Validation Batches: 16\n",
      "Batch Size: 256 --> Train Batches: 227, Validation Batches: 8\n",
      "Batch Size: 512 --> Train Batches: 114, Validation Batches: 4\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define batch sizes\n",
    "batch_sizes = [10, 25, 64, 128, 256, 512]\n",
    "\n",
    "# Store results\n",
    "dataloaders_info = []\n",
    "\n",
    "# Iterate over each dataset split\n",
    "for (train_set, val_set), (train_size, val_size) in zip(datasets_splits, splits):\n",
    "    print(f\"\\n=== Train: {train_size}, Validation: {val_size} ===\")\n",
    "    \n",
    "    # Iterate over different batch sizes\n",
    "    for batch_size in batch_sizes:\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        num_train_batches = len(train_loader)\n",
    "        num_val_batches = len(val_loader)\n",
    "        \n",
    "        dataloaders_info.append((train_size, val_size, batch_size, num_train_batches, num_val_batches))\n",
    "\n",
    "        print(f\"Batch Size: {batch_size} --> Train Batches: {num_train_batches}, Validation Batches: {num_val_batches}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 1. Transposed Shapes ===\n",
      "Original 2D Shape: torch.Size([4, 3]) --> Transposed: torch.Size([3, 4])\n",
      "Original 3D Shape: torch.Size([2, 4, 3]) --> Transposed: torch.Size([2, 3, 4])\n",
      "Original 5D Shape: torch.Size([2, 3, 4, 5, 6]) --> Transposed: torch.Size([2, 3, 4, 6, 5])\n"
     ]
    }
   ],
   "source": [
    "# Create random tensors\n",
    "tensor_2d = torch.rand(4, 3)   # Shape: (4,3)\n",
    "tensor_3d = torch.rand(2, 4, 3) # Shape: (2,4,3)\n",
    "tensor_5d = torch.rand(2, 3, 4, 5, 6) # Shape: (2,3,4,5,6)\n",
    "\n",
    "# Transpose tensors\n",
    "transposed_2d = tensor_2d.T  # Equivalent to torch.transpose(tensor_2d, 0, 1)\n",
    "transposed_3d = torch.transpose(tensor_3d, 1, 2) # Swap last two dimensions\n",
    "transposed_5d = torch.transpose(tensor_5d, 3, 4) # Swap last two dimensions\n",
    "\n",
    "# Print shapes after transposing\n",
    "print(\"\\n=== 1. Transposed Shapes ===\")\n",
    "print(\"Original 2D Shape:\", tensor_2d.shape, \"--> Transposed:\", transposed_2d.shape)\n",
    "print(\"Original 3D Shape:\", tensor_3d.shape, \"--> Transposed:\", transposed_3d.shape)\n",
    "print(\"Original 5D Shape:\", tensor_5d.shape, \"--> Transposed:\", transposed_5d.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2. Matrix Multiplication Results ===\n",
      "2D Matmul Result Shape: torch.Size([4, 5])\n",
      "3D Matmul Result Shape: torch.Size([2, 4, 2])\n",
      "5D Matmul Result Shape: torch.Size([2, 3, 4, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "# 2D Tensor Multiplication\n",
    "matmul_2d = torch.matmul(tensor_2d, torch.rand(3, 5))  # (4,3) x (3,5) -> (4,5)\n",
    "\n",
    "# 3D Tensor Multiplication\n",
    "matmul_3d = torch.matmul(tensor_3d, torch.rand(3, 2))  # (2,4,3) x (3,2) -> (2,4,2)\n",
    "\n",
    "# 5D Tensor Multiplication\n",
    "matmul_5d = torch.matmul(tensor_5d, torch.rand(6, 7))  # (2,3,4,5,6) x (6,7) -> (2,3,4,5,7)\n",
    "\n",
    "# Print shapes of results\n",
    "print(\"\\n=== 2. Matrix Multiplication Results ===\")\n",
    "print(\"2D Matmul Result Shape:\", matmul_2d.shape)\n",
    "print(\"3D Matmul Result Shape:\", matmul_3d.shape)\n",
    "print(\"5D Matmul Result Shape:\", matmul_5d.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D x 3D Matmul Not Possible: Expected size for first two dimensions of batch2 tensor to be: [2, 3] but got: [2, 4].\n",
      "3D x 5D Matmul Not Possible: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = torch.matmul(tensor_2d, tensor_3d)  # Should fail\n",
    "    print(\"2D x 3D Matmul Possible! Shape:\", result.shape)\n",
    "except RuntimeError as e:\n",
    "    print(\"2D x 3D Matmul Not Possible:\", e)\n",
    "\n",
    "try:\n",
    "    result = torch.matmul(tensor_3d, tensor_5d)  # Should fail\n",
    "    print(\"3D x 5D Matmul Possible! Shape:\", result.shape)\n",
    "except RuntimeError as e:\n",
    "    print(\"3D x 5D Matmul Not Possible:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
